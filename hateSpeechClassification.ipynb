{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedanta28/sentiment-analysis/blob/main/hateSpeechClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Installing Dependencies:"
      ],
      "metadata": {
        "id": "mYi2-uMS8eMe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVoiLN0mjpfO"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install emojis\n",
        "!pip install --upgrade google-api-python-client\n",
        "!pip install quica"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries:"
      ],
      "metadata": {
        "id": "qa5ikBNR8aCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from quica.quica import Quica\n",
        "import csv\n",
        "\n",
        "from googleapiclient import discovery\n",
        "API_KEY = 'PUT YOUR OWN API KEY HERE'\n",
        "client = discovery.build('commentanalyzer',\n",
        "                         'v1alpha1',\n",
        "                         developerKey=API_KEY,\n",
        "                         discoveryServiceUrl='https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1',\n",
        "                         static_discovery=False)"
      ],
      "metadata": {
        "id": "jyODHFcJtdk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "toxicBERT:"
      ],
      "metadata": {
        "id": "qEDvQMIN8Rmv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI-4DMTrkA2h"
      },
      "outputs": [],
      "source": [
        "def replace_emojis_with_words(text):\n",
        "  return emoji.demojize(text, delimiters=(\"\", \"\"))\n",
        "\n",
        "model = pipeline(model='unitary/toxic-bert')\n",
        "def predict(text):\n",
        "    return model([text])[0]['score']\n",
        "\n",
        "path = \"/content/asian hate crime.csv\" #Put the path name of the file here.\n",
        "filename = \"asian hate crime.csv\" #Put the name of the file here.\n",
        "df = pd.read_csv(path)\n",
        "toxic = list()\n",
        "toxic_binary = list()\n",
        "for i in  tqdm(range(len(df))):\n",
        "  text = re.sub(r'https?:\\/\\/\\S*', 'LINK', str(df.iloc[i].Tweet))\n",
        "  text = re.sub(r'\\B@\\w+', '@USER', text)\n",
        "  text = text.replace('\\n', ' ')\n",
        "  text = replace_emojis_with_words(text)\n",
        "\n",
        "  try:\n",
        "    toxic_score = predict(text)\n",
        "    toxic.insert(i, toxic_score)\n",
        "    if toxic_score >= 0.5:\n",
        "      toxic_binary.insert(i, 1)\n",
        "    else:\n",
        "      toxic_binary.insert(i, 0)\n",
        "  except:\n",
        "    print('Error at : ', i)\n",
        "\n",
        "df['toxic_bert'] = toxic\n",
        "df['toxic_bert_binary'] = toxic_binary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Perspective API:"
      ],
      "metadata": {
        "id": "8BteTD5o8VYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['perspective'] = 0\n",
        "index = list(df.columns).index('perspective')\n",
        "df['perspective_binary'] = 0\n",
        "index_binary = list(df.columns).index('perspective_binary')\n",
        "\n",
        "for i in tqdm(range(df.shape[0])):\n",
        "    text = re.sub(r'https?:\\/\\/\\S*', 'LINK', str(df.iloc[i].Tweet))\n",
        "    text = re.sub(r'\\B@\\w+', '@USER', text)\n",
        "    text = text.replace('\\n', ' ')\n",
        "    analyze_request = {'comment': { 'text': text},\n",
        "                       'requestedAttributes': {'TOXICITY': {}},\n",
        "                       'doNotStore': True}\n",
        "    \n",
        "    try:\n",
        "        response = client.comments().analyze(body=analyze_request).execute()\n",
        "        df.iat[i, index] = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
        "        if df.iat[i, index] >= 0.5:\n",
        "          df.iat[i, index_binary] = 1\n",
        "    except:\n",
        "        print('Error at : ', i)\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "df.to_csv(filename)"
      ],
      "metadata": {
        "id": "DaYetPEx8P3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Krippendorff's Alpha and finding the disaggrements:"
      ],
      "metadata": {
        "id": "PCa_DaXk8vPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/feminism.csv\" #Put the path name of the file here.\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "perspective_binary = []\n",
        "toxic_bert_binary = []\n",
        "disaggrements = []\n",
        "for i in tqdm(range(df.shape[0])):\n",
        "  # Discarding the Tweets which Perspective API call was not able to work.\n",
        "    if (df.iloc[i].perspective != 0.0):\n",
        "      toxic_bert_binary.append(df.iloc[i].toxic_bert_binary)\n",
        "      perspective_binary.append(df.iloc[i].perspective_binary)\n",
        "      # Collecting the tweets which the Models disaggreed on.\n",
        "      if (df.iloc[i].toxic_bert_binary != df.iloc[i].perspective_binary):\n",
        "        disaggrements.append([df.iloc[i, 1], df.iloc[i].User, df.iloc[i].Tweet, df.iloc[i].toxic_bert_binary, df.iloc[i].perspective_binary])\n",
        "\n",
        "\n",
        "df_aggrement = pd.DataFrame({\"toxic_bert_binary\" : toxic_bert_binary, \"perspective_binary\" : perspective_binary})\n",
        "quica = Quica(dataframe = df_aggrement)\n",
        "print(quica.get_results())\n",
        "\n",
        "Details = ['Unique ID', 'User', 'Tweet', 'toxic_bert_binary', 'perspective_binary']\n",
        "with open('disaggrements.csv', 'w', encoding='UTF8') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(Details)\n",
        "    write.writerows(disaggrements)"
      ],
      "metadata": {
        "id": "8kA7mOAC849x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOf1Q4c6/Zmk/wsgYLLb1r/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}